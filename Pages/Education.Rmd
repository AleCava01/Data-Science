---
title: "Education"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<img src="images/money_education.jfif" width="300" align="right"/>

# Income vs Education

## Data loading

```{r}
#importing libraries
library(GGally)
library(MASS)
library(car)
library(rgl)
#loading data
data = read.csv(file = "../Datasets/Income2.csv", header = T)
```

## Model A

```{r}
model_A = lm(Income ~ Education, data = data)
summary(model_A)

```

The model seems good: high R\^2 index and statistically significant parameters.

Let's do some diagnostics

```{r}
par(mfrow=c(2,2))
plot(model_A)
```

The model seems very good: good homoscedacity and good distribution of points in the Q-Q Plot along the diagonal, no leverage points...

I want to further investigate the Residual vs Fitted plot though

```{r}
ggplot(data, aes(x=model_A$fitted.values, y=scale(model_A$residuals)))+
  geom_point()+
  geom_smooth(method = "loess", formula="y~x")
```

This pattern seems a little bit suspicious to me. I'll define another model.

## Model B

```{r}
model_B = lm(Income ~ Education+I(Education^2)+I(Education^3), data = data)
summary(model_B)

```

R\^2 has increased. Predictors are all statistically significative. This model seems to be better than the previous one.

```{r}
par(mfrow=c(2,2))
plot(model_B)
shapiro.test(model_B$residuals)
```

Much better, but I see that point 1 is almost a leverage point.

## Model C

I'll try to create something like a smoothstep

```{r}
model_C = lm(Income ~ I(Education^4)+I(Education^5), data = data)
summary(model_C)

```

R\^2 slightly decreased but it's better than model A and the rest is still good.

```{r}
par(mfrow=c(2,2))
plot(model_C)
```

Point 1 is no more on the Cook's distance curve. Better.

Pattern in residuals vs fitted is again visible.

## Conclusion

```{r}
data$model_A_inc <- predict(model_A, data.frame(Education=data$Education))
data$model_B_inc <- predict(model_B, data.frame(Education=data$Education))
data$model_C_inc <- predict(model_C, data.frame(Education=data$Education))
df <- data.frame(Education=rep(data$Education,3), Income=data$Income,Prediction=c(data$model_A_inc,data$model_B_inc,data$model_C_inc), Predicted=c(rep("model A",30),rep("model B",30),rep("model C",30)))
df
ggplot(df, aes(x=Education, y=Prediction, color=Predicted))+
  geom_line(size=1.2)+
  geom_point(aes(x=Education, y=Income), color="black")+
  ylab("Income")

```

Model B and C seems much better than model A: there seem to be a diminishing marginal return between education and income. If you get moderately educated, you will obtain great improvements in terms of future income but, if you keep studying, you won't receive as much improvements as you got before.
